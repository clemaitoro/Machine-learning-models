{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 294 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from numpy.ma import indices\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(\"train\",\n",
    "                                              target_size=(64, 64),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode=\"categorical\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\"test\",\n",
    "                                                        target_size=(64, 64),\n",
    "                                                        batch_size=32,\n",
    "                                                        class_mode=\"categorical\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building convolutional neural network"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "1st Convolutional layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", input_shape=[64, 64, 3]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pooling layer, applying max pooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2nd Convolutional and pooling layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\"))\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Flattening layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Full connection layers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Output layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=2, activation=\"softmax\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compiling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the model and evaluating"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "10/10 [==============================] - 3s 153ms/step - loss: 0.7994 - accuracy: 0.5170 - val_loss: 0.6581 - val_accuracy: 0.5567\n",
      "Epoch 2/25\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.6547 - accuracy: 0.6259 - val_loss: 0.6224 - val_accuracy: 0.6701\n",
      "Epoch 3/25\n",
      "10/10 [==============================] - 1s 112ms/step - loss: 0.6198 - accuracy: 0.6837 - val_loss: 0.7115 - val_accuracy: 0.5670\n",
      "Epoch 4/25\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.6510 - accuracy: 0.6156 - val_loss: 0.8705 - val_accuracy: 0.4330\n",
      "Epoch 5/25\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.6589 - accuracy: 0.5680 - val_loss: 0.6259 - val_accuracy: 0.6392\n",
      "Epoch 6/25\n",
      "10/10 [==============================] - 1s 115ms/step - loss: 0.5975 - accuracy: 0.6701 - val_loss: 0.6037 - val_accuracy: 0.6598\n",
      "Epoch 7/25\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.5657 - accuracy: 0.7109 - val_loss: 0.6047 - val_accuracy: 0.6701\n",
      "Epoch 8/25\n",
      "10/10 [==============================] - 1s 104ms/step - loss: 0.5560 - accuracy: 0.7313 - val_loss: 0.6814 - val_accuracy: 0.6804\n",
      "Epoch 9/25\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.5182 - accuracy: 0.7279 - val_loss: 0.5395 - val_accuracy: 0.7113\n",
      "Epoch 10/25\n",
      "10/10 [==============================] - 1s 105ms/step - loss: 0.5364 - accuracy: 0.7245 - val_loss: 0.4855 - val_accuracy: 0.7320\n",
      "Epoch 11/25\n",
      "10/10 [==============================] - 1s 108ms/step - loss: 0.4767 - accuracy: 0.7517 - val_loss: 0.5971 - val_accuracy: 0.7423\n",
      "Epoch 12/25\n",
      "10/10 [==============================] - 1s 117ms/step - loss: 0.4331 - accuracy: 0.8197 - val_loss: 0.5520 - val_accuracy: 0.7216\n",
      "Epoch 13/25\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.4655 - accuracy: 0.7891 - val_loss: 0.6800 - val_accuracy: 0.7010\n",
      "Epoch 14/25\n",
      "10/10 [==============================] - 1s 106ms/step - loss: 0.4941 - accuracy: 0.7381 - val_loss: 0.7040 - val_accuracy: 0.6289\n",
      "Epoch 15/25\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4693 - accuracy: 0.7755 - val_loss: 0.5554 - val_accuracy: 0.7629\n",
      "Epoch 16/25\n",
      "10/10 [==============================] - 1s 114ms/step - loss: 0.4196 - accuracy: 0.8095 - val_loss: 0.5107 - val_accuracy: 0.7320\n",
      "Epoch 17/25\n",
      "10/10 [==============================] - 1s 103ms/step - loss: 0.3536 - accuracy: 0.8639 - val_loss: 0.5283 - val_accuracy: 0.7629\n",
      "Epoch 18/25\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.4357 - accuracy: 0.7993 - val_loss: 0.5413 - val_accuracy: 0.7113\n",
      "Epoch 19/25\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3935 - accuracy: 0.8231 - val_loss: 0.4625 - val_accuracy: 0.7835\n",
      "Epoch 20/25\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3765 - accuracy: 0.8367 - val_loss: 0.4915 - val_accuracy: 0.7320\n",
      "Epoch 21/25\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3464 - accuracy: 0.8571 - val_loss: 0.5264 - val_accuracy: 0.7526\n",
      "Epoch 22/25\n",
      "10/10 [==============================] - 1s 99ms/step - loss: 0.3571 - accuracy: 0.8367 - val_loss: 0.6743 - val_accuracy: 0.7216\n",
      "Epoch 23/25\n",
      "10/10 [==============================] - 1s 102ms/step - loss: 0.3731 - accuracy: 0.8401 - val_loss: 0.5466 - val_accuracy: 0.7010\n",
      "Epoch 24/25\n",
      "10/10 [==============================] - 1s 100ms/step - loss: 0.3296 - accuracy: 0.8810 - val_loss: 0.4948 - val_accuracy: 0.7320\n",
      "Epoch 25/25\n",
      "10/10 [==============================] - 1s 101ms/step - loss: 0.3361 - accuracy: 0.8707 - val_loss: 0.5591 - val_accuracy: 0.7732\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x21bb9307400>"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_set, validation_data=test_set ,epochs=25)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Making single prediction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 74ms/step\n",
      "Predicted class: apple\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "\n",
    "test_image = Image.open(\"test/apples/img_p1_76.jpeg\")\n",
    "test_image = test_image.resize((64, 64))\n",
    "\n",
    "test_image = tf.keras.preprocessing.image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "train_set.class_indices\n",
    "if result[0][0] > result[0][1]:\n",
    "    predicted_class = \"apple\"\n",
    "else:\n",
    "    predicted_class = \"tomato\"\n",
    "print(\"Predicted class:\", predicted_class)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
